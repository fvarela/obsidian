## From Files to Dataframes
### Read a csv:

* InferSchema option: You can set it to True and not provide a schema. It would take longer to run and it is prone to errors. Use only for exploration and once you know how the data is formatted provide the schema:

```

'''

Declare the schema and load the file to DF:

'''

circuits_schema = StructType(fields =
      [StructField("circuitId", IntegerType(), False),
      StructField("circuitRef", StringType(), False),
      StructField("name", StringType(), False),
      StructField("location", StringType(), False),
      StructField("country", StringType(), False),
      StructField("lat", DoubleType(), False),
      StructField("lng", DoubleType(), False),
      StructField("alt", IntegerType(), False),
      StructField("url", StringType(), False)])
      
# .option("inferSchema", True) \
circuits_df = spark.read \
.option("header", True) \
.schema(circuits_schema) \
.csv(f"{raw_folder_path}/circuits.csv")

```

### Read a csv folder
Similar to reading a single csv file. Just use the path where the csv are located instead of the csv path:
```
lap_times_df = spark.read \
.schema(lap_times_schema) \
.csv(f"{raw_folder_path}/lap_times")
```

### Read a Parquet

`df = spark.read.parquet("/mnt/formula1dlfvv/processed/circuits")`

If you want to filter inside the parquet to get only the data coming from one file use the .filter:

```
results_df = spark.read.parquet(f"{processed_folder_path}/results") \
.filter(f"file_date = '{v_file_date}'") \
.withColumnRenamed("time", "race_time")
```


### Read a json
```
constructors_schema = "constructorId INT, constructorRef STRING, name STRING, nationality STRING, url STRING"

constructor_df = spark.read \
  .schema(constructors_schema) \
  .json("/mnt/formula1dlfvv/raw/constructors.json")
```

### Read a nested json (check the schema):

```
name_schema = StructType(fields=[StructField("forename", StringType(), True),
                         StructField("surname", StringType(), True)])

drivers_schema = StructType(fields=[StructField("driverId", IntegerType(), True),
                         StructField("driverRef", StringType(), True),
                         StructField("number", IntegerType(), True),
                         StructField("code", StringType(), True),
                         StructField("name", name_schema),
                         StructField("dob", DateType(), True),
                         StructField("nationality", StringType(), True),
                         StructField("url", StringType(), True)                  
                         ])                      
  
drivers_df = spark.read \
  .schema(drivers_schema) \
  .json("/mnt/formula1dlfvv/raw/drivers.json")

```

### Read from a (previously saved) Table:
```
	df = spark.sql("SELECT * FROM my_table")
```


