
### ABFS vs DBFS
ABFS:
	Cheaper
	Integrates better with Azure
	Supports hierarchical namespaces. Important for data lakes!
DBFS
	Does not support hierarchical namespaces. (It simulate it, but it is not the same)

### ABFS
In order to access Azure Storage File System:

* Set up necessary configuration:
 `spark.conf.set("fs.azure.account.key.<storage-account>.dfs.core.windows.net"."<access key>")`

* Use the `abfs` driver to access the files:
abfs: Azure Blob File System
That is the recommended way to connect to an Azure Storage Account
It is optimized for big data analytics
Offers better security
The abfs paths look like this:
	`abfs[s]://container@storage_account_name.dfs.core.windows.net/folder_path/file_name`

Example on how to list the files and folders on a container:
	`dbutils.fs.ls("abfss://demo@formula1dl.dfs.core.windows.net/")`


### DBFS
Databricks File System
Faster than abfs but limited to cluster HD storage. Tipically 64Gb to 256Gb.
It doesn't fully mimic a local file system.
That is native to Databricks so it is the best choice (over abfs) if your solution depends heavily on Spark.

### In order to mount an Azure Data Lake in DBFS:
This would allow you to access the data without credentials
You can also use File explorer semantics (/mnt/mydata) instead of the long URL
Things you need:
![[Pasted image 20240129175325.png]]			

Then you can use the mounted container like this:
![[Pasted image 20240129175436.png]]

### In order to list all the mounts:
`dbutils.fs.mounts()`

![[Pasted image 20240129180121.png]]

### In order to unmount a volume:
`dbutils.fs.unmount('/mnt/python-libraries')`

### WASBS
Windows Azure Storage Blob (Secure)
commonly used where secure access to Blob Storage is needed without the additional features of ADLS Gen2
ABFS performs better. 
WSBS could be enough if ADLS Gen2 is not needed.


